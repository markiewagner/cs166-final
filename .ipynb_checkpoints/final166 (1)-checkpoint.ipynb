{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "h6uihjZsJVd1"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "d285GeaR6qB6"
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import hashlib\n",
    "import json "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DjukLsOE6rVJ"
   },
   "outputs": [],
   "source": [
    "class CountMinSketch:\n",
    "    def __init__(self, eps, delta):\n",
    "        self.eps = eps\n",
    "        self.delta = delta\n",
    "        self.w = math.ceil(np.exp(1) / eps)\n",
    "        self.d = math.ceil(np.log(1 / delta))\n",
    "        self.tables = np.zeros((self.d, self.w))\n",
    "        self.backup = {}\n",
    "\n",
    "    def compute_hash(self, value, table_no):\n",
    "        fn = hashlib.md5()\n",
    "        inp = str(value) + str(0) + str(table_no)\n",
    "        fn.update(inp.encode())\n",
    "        out = int(fn.hexdigest(), 16)\n",
    "        return out % self.w\n",
    "\n",
    "    def count(self, value):\n",
    "        if str(value) in self.backup: \n",
    "            self.backup[str(value)] = self.backup[str(value)] + 1\n",
    "        else:\n",
    "            self.backup[str(value)] = 1\n",
    "        for i in range(self.d):\n",
    "            j = self.compute_hash(value, i)\n",
    "            self.tables[i][j] = self.tables[i][j] + 1\n",
    "\n",
    "    def estimate(self, value):\n",
    "        ests = []\n",
    "        for i in range(self.d):\n",
    "            j = self.compute_hash(value, i)\n",
    "            ests.append(self.tables[i][j])\n",
    "        return min(ests)\n",
    "\n",
    "    def real_estimate(self, value):\n",
    "        if str(value) in self.backup: return self.backup[str(value)]\n",
    "        return -1\n",
    "\n",
    "    def compute_size(self):\n",
    "        size = 0\n",
    "        for key in self.backup:\n",
    "            size += abs(self.backup[key])\n",
    "        return size\n",
    "\n",
    "    def save_counts(self, count_filename='counts.txt', actual_filename='backups.txt'):\n",
    "        np.savetxt(count_filename, self.tables)\n",
    "        with open(actual_filename, 'w') as fp: json.dump(self.backup, fp)\n",
    "\n",
    "    def load_counts(self, count_filename='counts.txt', actual_filename='backups.txt'):\n",
    "        with open(actual_filename, 'r') as fp: \n",
    "            temp = json.load(fp)\n",
    "            self.backup = temp\n",
    "        self.tables = np.loadtxt(count_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XF1hVGvsOcdC"
   },
   "outputs": [],
   "source": [
    "import scipy.stats as stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gMmPiEExOkEU"
   },
   "outputs": [],
   "source": [
    "def generate_sample(n=1000, dist='uniform', loc=0, scale=1000, lambda_=5, s=1):\n",
    "  if dist == 'uniform':\n",
    "    float_sample = stats.uniform.rvs(loc, scale, n)\n",
    "    return [int(el) for el in float_sample]\n",
    "  if dist == 'zipf':\n",
    "    float_sample = stats.zipf.rvs(loc + 1, size=n)\n",
    "    return [int(el) for el in float_sample]\n",
    "  if dist == 'exp':\n",
    "    float_sample = stats.planck.rvs(lambda_, size=n)\n",
    "    return [int(el) for el in float_sample]\n",
    "  if dist == 'lognorm':\n",
    "    float_sample = stats.lognorm.rvs(s=scale, size=n)\n",
    "    return [int(el) for el in float_sample]\n",
    "  if dist == 'geometric':\n",
    "    float_sample =  stats.geom.rvs(p, size=n)\n",
    "    return [int(el) for el in float_sample]\n",
    "  elif dist == 'normal':\n",
    "    float_sample = stats.norm.rvs(loc, scale, n)\n",
    "    return [int(el) for el in float_sample]\n",
    "  else:\n",
    "    return -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KHamIwm2QVqn"
   },
   "outputs": [],
   "source": [
    "cms = CountMinSketch(0.03, 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_CJT7CCjQpJc"
   },
   "outputs": [],
   "source": [
    "uniform_sample = generate_sample()\n",
    "for el in uniform_sample:\n",
    "  cms.count(el)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yhps1WT_VNLC"
   },
   "outputs": [],
   "source": [
    "def compute_error_prob(cms, data, n):\n",
    "  err = []\n",
    "  for el in data:\n",
    "    err.append(cms.estimate(el) - cms.real_estimate(el))\n",
    "  avg_err = sum(err) / len(err)\n",
    "  max_err = max(err)\n",
    "  exceed = 0\n",
    "  for el in err:\n",
    "    if el > cms.eps * n:\n",
    "      exceed += 1\n",
    "  return exceed / len(err), err"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "E8780hl2WFs_"
   },
   "outputs": [],
   "source": [
    "def load_data(cms, data):\n",
    "  for el in data:\n",
    "    cms.count(el)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XYjH-xvDWKrR"
   },
   "outputs": [],
   "source": [
    "def run_experiment():\n",
    "  n = 1000\n",
    "  eps = 0.01\n",
    "  min_delta = 0.01\n",
    "  max_delta = 0.1\n",
    "  deltas = np.linspace(min_delta, max_delta, 10).tolist()\n",
    "  # deltas = [0.05, 0.1, 0.15, 0.2, 0.25, 0.3, 0.35, 0.4, 0.45, 0.5, 0.55, 0.6, 0.65, 0.7, 0.75, 0.8, 0.85, 0.9, 0.95, 1]\n",
    "  ps = []\n",
    "  for delta in deltas:\n",
    "    probs = 0\n",
    "    for i in range(3):\n",
    "      cms = CountMinSketch(eps, delta)\n",
    "      print(cms.w)\n",
    "      dt = generate_sample(n)\n",
    "      load_data(cms, dt)\n",
    "      p, err = compute_error_prob(cms, dt, n)\n",
    "      print(err)\n",
    "      probs += p\n",
    "    probs /= 3\n",
    "    ps.append(probs)\n",
    "  return deltas, ps, err\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 265
    },
    "colab_type": "code",
    "id": "e0HVqsMNhTQp",
    "outputId": "bd679682-3fd8-4fb6-8fb9-f27f9d1bf873"
   },
   "outputs": [],
   "source": [
    "# VISUALIZE ERROR PROBABILITY VS DELTA\n",
    "\n",
    "# compute empirical probability of error exceeding the threshold\n",
    "def compute_error_prob(cms, data, n):\n",
    "  err = []\n",
    "  for el in data:\n",
    "    err.append(cms.estimate(el) - cms.real_estimate(el))\n",
    "  avg_err = sum(err) / len(err)\n",
    "  max_err = max(err)\n",
    "  exceed = 0\n",
    "  for el in err:\n",
    "    if el > cms.eps * n:\n",
    "      exceed += 1\n",
    "  p = exceed / len(err)\n",
    "  return p, avg_err, max_err, err\n",
    "\n",
    "# run experiments on 10 values of delta interpolated between (min_delta, max_delta) and compute array of corresponding error probabilities\n",
    "def error_prob_vs_delta(n=100000, eps=0.4, min_delta=0.01, max_delta=0.1):\n",
    "  deltas = np.linspace(min_delta, max_delta, 10).tolist()\n",
    "  # deltas = [0.05, 0.1, 0.15, 0.2, 0.25, 0.3, 0.35, 0.4, 0.45, 0.5, 0.55, 0.6, 0.65, 0.7, 0.75, 0.8, 0.85, 0.9, 0.95, 1]\n",
    "  ps = []\n",
    "  for delta in deltas:\n",
    "    probs = 0\n",
    "    # Average probabilities across 3 trials\n",
    "    for i in range(3):\n",
    "      cms = CountMinSketch(eps, delta)\n",
    "      dt = generate_sample(n)\n",
    "      load_data(cms, dt)\n",
    "      p, avg_err, max_err, err = compute_error_prob(cms, dt, n)\n",
    "      probs += p\n",
    "    probs /= 3\n",
    "    ps.append(probs)\n",
    "  return deltas, ps\n",
    "\n",
    "# graphing helper function\n",
    "def graph_error_prob_vs_delta(deltas, ps, filename=\"p_vs_delta.png\"):\n",
    "  plt.scatter(deltas, ps)\n",
    "  plt.show()\n",
    "\n",
    "# actual code to run experiment:\n",
    "deltas, ps = error_prob_vs_delta()\n",
    "graph_error_prob_vs_delta(deltas, ps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 347
    },
    "colab_type": "code",
    "id": "__raxykvnDWY",
    "outputId": "db6714e0-c1b1-4282-e65f-fecc48228318"
   },
   "outputs": [],
   "source": [
    "# VISUALIZE HOW ERROR DISTRIBUTION CHANGES WITH EPS, DELTA, N ON UNIFORM DATA\n",
    "eps = 0.01\n",
    "delta = 0.05\n",
    "n = 10000\n",
    "threshold = eps * n\n",
    "sample = generate_sample(n=n, dist='normal', loc=0, scale=100)\n",
    "\n",
    "cms = CountMinSketch(eps, delta)\n",
    "load_data(cms, sample)\n",
    "\n",
    "p, avg_err, max_err, err = compute_error_prob(cms, sample, n)\n",
    "\n",
    "print(\"Average Error: \" + str(avg_err))\n",
    "print(\"Maximum Error: \" + str(max_err))\n",
    "print(\"Acceptable Threshold: \" + str(threshold))\n",
    "print(\"Proportion of Errors Exceeding Threshold: \" + str(p))\n",
    "\n",
    "plt.scatter(sample, err, label = \"Errors\")\n",
    "plt.ylabel(\"Error Magnitude\")\n",
    "plt.xlabel(\"Data Point\")\n",
    "plt.plot([min(sample), max(sample)], [threshold, threshold], color='red', label = \"Threshold\")\n",
    "plt.legend(loc=1)\n",
    "plt.savefig(\"normal.png\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 347
    },
    "colab_type": "code",
    "id": "dBEn8e2YpmFt",
    "outputId": "b99f20bd-469b-4c89-9c88-ccf44f5d8054"
   },
   "outputs": [],
   "source": [
    "# VISUALIZE HOW ERROR CHANGES BY COMPRESSING THE NORMAL DISTRIBUTION\n",
    "eps = 0.01\n",
    "delta = 0.05\n",
    "n = 10000\n",
    "threshold = eps * n\n",
    "\n",
    "mean = 0\n",
    "sd = 100\n",
    "sample = generate_sample(n=n, dist='normal', loc=mean, scale=sd)\n",
    "\n",
    "cms = CountMinSketch(eps, delta)\n",
    "load_data(cms, sample)\n",
    "\n",
    "p, avg_err, max_err, err = compute_error_prob(cms, sample, n)\n",
    "\n",
    "print(\"Average Error: \" + str(avg_err))\n",
    "print(\"Maximum Error: \" + str(max_err))\n",
    "print(\"Acceptable Threshold: \" + str(threshold))\n",
    "print(\"Proportion of Errors Exceeding Threshold: \" + str(p))\n",
    "\n",
    "fig, (f1, f2, f3) = plt.subplots(1,3)\n",
    "fig.set_size_inches(15, 4)\n",
    "\n",
    "f1.scatter(sample, err, label=\"Errors\")\n",
    "f1.plot([min(sample), max(sample)], [threshold, threshold], color='red', label=\"Threshold\")\n",
    "f1.legend(loc=1)\n",
    "f1.set(ylabel=\"Error\", xlabel=\"Data Point\")\n",
    "f2.hist(sample)\n",
    "f2.set(ylabel=\"Count\", xlabel=\"Data Point\")\n",
    "f3.hist(err)\n",
    "f3.set(ylabel=\"Count\", xlabel=\"Error Magnitude\")\n",
    "fig.savefig(\"normal2.png\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 279
    },
    "colab_type": "code",
    "id": "BIJMH0gpsd95",
    "outputId": "00a50f31-8968-492d-dec5-e73c3d0d20ee"
   },
   "outputs": [],
   "source": [
    "# Plot Average Error vs. SD\n",
    "eps = 0.01\n",
    "delta = 0.05\n",
    "n = 1000\n",
    "threshold = eps * n\n",
    "\n",
    "mean=0\n",
    "min_sd=1\n",
    "max_sd=100\n",
    "\n",
    "def error_vs_sd(eps=0.01, delta=0.05, n=1000, mean=0, min_sd=50, max_sd=500):\n",
    "  sds = np.linspace(min_sd, max_sd).tolist()\n",
    "  avgs = []\n",
    "  maxs = []\n",
    "  ps = []\n",
    "\n",
    "  for sd in sds:\n",
    "    sample = generate_sample(n=1000, dist='normal', loc=mean, scale=sd)\n",
    "    cms = CountMinSketch(eps, delta)\n",
    "    load_data(cms, sample)\n",
    "    p, avg_err, max_err, err = compute_error_prob(cms, sample, n)\n",
    "    avgs.append(avg_err)\n",
    "    maxs.append(max_err)\n",
    "    ps.append(p)\n",
    "  \n",
    "  threshold = eps * n\n",
    "  return sds, avgs, maxs, ps, threshold\n",
    "\n",
    "# actual code\n",
    "sds, avgs, maxs, ps, threshold = error_vs_sd(eps, delta, n, mean, min_sd, max_sd)\n",
    "fig, (f1, f2, f3) = plt.subplots(1, 3)\n",
    "fig.set_size_inches(15, 4)\n",
    "f1.scatter(sds, avgs)\n",
    "f1.plot([min(sds), max(sds)], [threshold, threshold], color='red')\n",
    "f1.set(xlabel=\"Standard Deviation\", ylabel=\"Average Error\")\n",
    "f2.scatter(sds, maxs)\n",
    "f2.plot([min(sds), max(sds)], [threshold, threshold], color='red')\n",
    "f2.set(ylabel=\"Maximum Error\", xlabel=\"Standard Deviation\")\n",
    "f3.scatter(sds, ps)\n",
    "f3.plot([min(sds), max(sds)], [delta, delta], color='red')\n",
    "f3.set(ylabel=\"Proportion of Intolerable Errors\", xlabel=\"Standard Deviation\")\n",
    "plt.savefig(\"3panel.png\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5tpmhWlYXeMP"
   },
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "from collections import Counter\n",
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Twc9l36DXtJX"
   },
   "outputs": [],
   "source": [
    "class LearnedCountMinSketch:\n",
    "    def __init__(self, eps, delta, train_data):\n",
    "        self.eps = eps\n",
    "        self.delta = delta\n",
    "        self.cms = CountMinSketch(eps, delta)\n",
    "\n",
    "        # set model\n",
    "        X_train = train_data[0]\n",
    "        Y_train = train_data[1]\n",
    "        self.model = MLPClassifier(hidden_layer_sizes=(30, 40))\n",
    "        self.model.fit(X_train.reshape(-1, 1), np.ravel(Y_train))\n",
    "        self.perfect = {}\n",
    "\n",
    "    def count(self, value):\n",
    "        if (self.model.predict(np.array([value]).reshape(-1, 1)) == 1):\n",
    "            if str(value) in self.perfect:\n",
    "                self.perfect[str(value)] = self.perfect[str(value)] + 1\n",
    "            else:\n",
    "                self.perfect[str(value)] = 1\n",
    "        else:\n",
    "            self.cms.count(value)\n",
    "\n",
    "    def estimate(self, value):\n",
    "        if (self.model.predict(np.array([value]).reshape(-1, 1)) == 1):\n",
    "            if str(value) in self.perfect: return self.perfect[str(value)]\n",
    "            return 0\n",
    "        else:\n",
    "            return self.cms.estimate(value)\n",
    "\n",
    "    def real_estimate(self, value):\n",
    "        if str(value) in self.perfect: return self.perfect[str(value)]\n",
    "        if str(value) in self.cms.backup: return self.cms.backup[str(value)]\n",
    "        return -1\n",
    "\n",
    "    def compute_size(self):\n",
    "        size = 0\n",
    "        for key in self.cms.backup:\n",
    "            size += abs(self.cms.backup[key])\n",
    "        for key in self.perfect:\n",
    "            size += abs(self.perfect[key])\n",
    "        return size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bdG4-61zX0gp"
   },
   "outputs": [],
   "source": [
    "# label data --> threshold is what proportion of data points you want to call \"heavy hitters\"\n",
    "def label_sample(sample, p = 0.05):\n",
    "    n = len(sample)\n",
    "    n_distinct = len(Counter(sample).keys())\n",
    "    num = int(n_distinct * p)\n",
    "    X_train = np.array(sample)\n",
    "    Y_train = np.zeros_like(X_train)\n",
    "    hh = Counter(sample).most_common(num)\n",
    "    hh = set([el[0] for el in hh])\n",
    "    for i in range(n):\n",
    "        if X_train[i] in hh:\n",
    "            Y_train[i] = 1\n",
    "    return X_train, Y_train, hh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 482
    },
    "colab_type": "code",
    "id": "Qlba3-brYAqq",
    "outputId": "6e060f7c-58f0-4d6f-a369-1e78153beb6c"
   },
   "outputs": [],
   "source": [
    "# VISUALIZE HOW ERROR DISTRIBUTION CHANGES WITH EPS, DELTA, N ON UNIFORM DATA\n",
    "eps = 0.01\n",
    "delta = 0.05\n",
    "n = 1000\n",
    "threshold = eps * n\n",
    "sample = generate_sample(n=n)\n",
    "X_tr, Y_tr, hh = label_sample(sample, p = 0.3)\n",
    "\n",
    "lcms = LearnedCountMinSketch(eps, delta, [X_tr, Y_tr])\n",
    "cms = CountMinSketch(eps, delta)\n",
    "\n",
    "load_data(lcms, sample)\n",
    "load_data(cms, sample)\n",
    "\n",
    "p1, avg_err1, max_err1, err1 = compute_error_prob(cms, sample, n)\n",
    "p2, avg_err2, max_err2, err2 = compute_error_prob(lcms, sample, n)\n",
    "\n",
    "print(\"Regular Count Min Sketch:\")\n",
    "print(\"Average Error: \" + str(avg_err1))\n",
    "print(\"Maximum Error: \" + str(max_err1))\n",
    "print(\"Acceptable Threshold: \" + str(threshold))\n",
    "print(\"Proportion of Errors Exceeding Threshold: \" + str(p1))\n",
    "print(\"\\nLearned Count Min Sketch:\")\n",
    "print(\"Average Error: \" + str(avg_err2))\n",
    "print(\"Maximum Error: \" + str(max_err2))\n",
    "print(\"Acceptable Threshold: \" + str(threshold))\n",
    "print(\"Proportion of Errors Exceeding Threshold: \" + str(p2))\n",
    "\n",
    "fig, (f1, f2) = plt.subplots(1, 2)\n",
    "fig.set_size_inches(10, 4)\n",
    "f1.hist(err1)\n",
    "# f1.scatter(sample, err1)\n",
    "f1.set(title=\"Count-Min Sketch\", xlabel=\"Error\", ylabel=\"Frequency\")\n",
    "# f1.plot([min(sample), max(sample)], [threshold, threshold], color='red')\n",
    "# f2.scatter(sample, err2)\n",
    "f2.hist(err2)\n",
    "f2.set(title=\"Learned Count-Min Sketch\", xlabel=\"Error\", ylabel=\"Frequency\")\n",
    "# f2.plot([min(sample), max(sample)], [threshold, threshold], color='red')\n",
    "fig.savefig(\"uniform_comparison.png\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 482
    },
    "colab_type": "code",
    "id": "HSn9upgvkpFm",
    "outputId": "194a8ceb-0310-4c9f-aad0-14b5bd8ac38b"
   },
   "outputs": [],
   "source": [
    "# VISUALIZE HOW ERROR DISTRIBUTION CHANGES WITH EPS, DELTA, N ON NORMAL DATA\n",
    "eps = 0.01\n",
    "delta = 0.05\n",
    "n = 1000\n",
    "threshold = eps * n\n",
    "\n",
    "p = 0.2\n",
    "\n",
    "mean = 0\n",
    "sd = 100\n",
    "\n",
    "sample = generate_sample(n=n, dist='normal', loc=mean, scale=sd)\n",
    "X_tr, Y_tr, hh = label_sample(sample, p)\n",
    "\n",
    "lcms = LearnedCountMinSketch(eps, delta, [X_tr, Y_tr])\n",
    "cms = CountMinSketch(eps, delta)\n",
    "\n",
    "load_data(lcms, sample)\n",
    "load_data(cms, sample)\n",
    "\n",
    "p1, avg_err1, max_err1, err1 = compute_error_prob(cms, sample, n)\n",
    "p2, avg_err2, max_err2, err2 = compute_error_prob(lcms, sample, n)\n",
    "\n",
    "print(\"Regular Count Min Sketch:\")\n",
    "print(\"Average Error: \" + str(avg_err1))\n",
    "print(\"Maximum Error: \" + str(max_err1))\n",
    "print(\"Acceptable Threshold: \" + str(threshold))\n",
    "print(\"Proportion of Errors Exceeding Threshold: \" + str(p1))\n",
    "print(\"\\nLearned Count Min Sketch:\")\n",
    "print(\"Average Error: \" + str(avg_err2))\n",
    "print(\"Maximum Error: \" + str(max_err2))\n",
    "print(\"Acceptable Threshold: \" + str(threshold))\n",
    "print(\"Proportion of Errors Exceeding Threshold: \" + str(p2))\n",
    "\n",
    "fig, (f1, f2) = plt.subplots(1, 2)\n",
    "fig.set_size_inches(10, 4)\n",
    "f1.hist(err1)\n",
    "f1.set(title=\"Count-Min Sketch\", xlabel=\"Error\", ylabel=\"Frequency\")\n",
    "# f1.scatter(sample, err1)\n",
    "# f1.plot([min(sample), max(sample)], [threshold, threshold], color='red')\n",
    "# f2.scatter(sample, err2)\n",
    "f2.hist(err2)\n",
    "f2.set(title=\"Learned Count-Min Sketch\", xlabel=\"Error\", ylabel=\"Frequency\")\n",
    "# f2.plot([min(sample), max(sample)], [threshold, threshold], color='red')\n",
    "fig.savefig(\"normal_comparison.png\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lPAE-zneG0MV"
   },
   "outputs": [],
   "source": [
    "class RuleCountMinSketch:\n",
    "    def __init__(self, eps, delta, hh):\n",
    "        self.eps = eps\n",
    "        self.delta = delta\n",
    "        self.cms = CountMinSketch(eps, delta)\n",
    "        self.hh = hh\n",
    "        self.perfect = {}\n",
    "\n",
    "    def count(self, value):\n",
    "        if value in self.hh:\n",
    "            if str(value) in self.perfect:\n",
    "                self.perfect[str(value)] = self.perfect[str(value)] + 1\n",
    "            else:\n",
    "                self.perfect[str(value)] = 1\n",
    "        else:\n",
    "            self.cms.count(value)\n",
    "\n",
    "    def estimate(self, value):\n",
    "        if (value in self.hh):\n",
    "            if str(value) in self.perfect: return self.perfect[str(value)]\n",
    "            return 0\n",
    "        else:\n",
    "            return self.cms.estimate(value)\n",
    "\n",
    "    def real_estimate(self, value):\n",
    "        if str(value) in self.perfect: return self.perfect[str(value)]\n",
    "        if str(value) in self.cms.backup: return self.cms.backup[str(value)]\n",
    "        return -1\n",
    "\n",
    "    def compute_size(self):\n",
    "        size = 0\n",
    "        for key in self.cms.backup:\n",
    "            size += abs(self.cms.backup[key])\n",
    "        for key in self.perfect:\n",
    "            size += abs(self.perfect[key])\n",
    "        return size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 482
    },
    "colab_type": "code",
    "id": "RZtejoHQHFp6",
    "outputId": "ea15aa65-4a91-4780-acef-2a84d965872c"
   },
   "outputs": [],
   "source": [
    "# VISUALIZE HOW ERROR DISTRIBUTION CHANGES WITH EPS, DELTA, N ON NORMAL DATA\n",
    "eps = 0.01\n",
    "delta = 0.05\n",
    "n = 1000\n",
    "threshold = eps * n\n",
    "\n",
    "p = 0.2\n",
    "\n",
    "mean = 0\n",
    "sd = 100\n",
    "\n",
    "sample = generate_sample(n=n, dist='normal', loc=mean, scale=sd)\n",
    "X_tr, Y_tr, hh = label_sample(sample, p)\n",
    "\n",
    "rcms = RuleCountMinSketch(eps, delta, hh)\n",
    "cms = CountMinSketch(eps, delta)\n",
    "\n",
    "load_data(rcms, sample)\n",
    "load_data(cms, sample)\n",
    "\n",
    "p1, avg_err1, max_err1, err1 = compute_error_prob(cms, sample, n)\n",
    "p2, avg_err2, max_err2, err2 = compute_error_prob(rcms, sample, n)\n",
    "\n",
    "print(\"Regular Count Min Sketch:\")\n",
    "print(\"Average Error: \" + str(avg_err1))\n",
    "print(\"Maximum Error: \" + str(max_err1))\n",
    "print(\"Acceptable Threshold: \" + str(threshold))\n",
    "print(\"Proportion of Errors Exceeding Threshold: \" + str(p1))\n",
    "print(\"\\nLearned Count Min Sketch:\")\n",
    "print(\"Average Error: \" + str(avg_err2))\n",
    "print(\"Maximum Error: \" + str(max_err2))\n",
    "print(\"Acceptable Threshold: \" + str(threshold))\n",
    "print(\"Proportion of Errors Exceeding Threshold: \" + str(p2))\n",
    "\n",
    "fig, (f1, f2) = plt.subplots(1, 2)\n",
    "fig.set_size_inches(10, 4)\n",
    "f1.hist(err1)\n",
    "f1.set(title=\"Count-Min Sketch\", xlabel=\"Error\", ylabel=\"Frequency\")\n",
    "# f1.scatter(sample, err1)\n",
    "# f1.plot([min(sample), max(sample)], [threshold, threshold], color='red')\n",
    "# f2.scatter(sample, err2)\n",
    "f2.hist(err2)\n",
    "f2.set(title=\"Rule Count-Min Sketch\", xlabel=\"Error\", ylabel=\"Frequency\")\n",
    "# f2.plot([min(sample), max(sample)], [threshold, threshold], color='red')\n",
    "fig.savefig(\"rule_comparison.png\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 279
    },
    "colab_type": "code",
    "id": "U0uWy9J3J7L1",
    "outputId": "d005e6b4-10b3-4380-854f-ee0f6b9b7962"
   },
   "outputs": [],
   "source": [
    "eps = 0.01\n",
    "delta = 0.05\n",
    "n = 1000\n",
    "threshold = eps * n\n",
    "\n",
    "min_p = 0\n",
    "max_p = 1\n",
    "\n",
    "mean = 0\n",
    "sd = 100\n",
    "\n",
    "def compute_avg_errors_vs_ps(n=1000, mean=0, sd=100, min_p = 0.1, max_p = 0.9, num_p = 40):\n",
    "  sample = generate_sample(n,dist='normal', loc=mean, scale=sd)\n",
    "  ps = np.linspace(min_p, max_p, num_p).tolist()\n",
    "  avgs = []\n",
    "  for p in ps:\n",
    "    X_tr, Y_tr, hh = label_sample(sample, p)\n",
    "    rcms = RuleCountMinSketch(eps, delta, hh)\n",
    "    load_data(rcms, sample)\n",
    "    _, avg_err, _, _ = compute_error_prob(rcms, sample, n)\n",
    "    avgs.append(avg_err)\n",
    "  return ps, avgs\n",
    "\n",
    "ps, avgs = compute_avg_errors_vs_ps()\n",
    "plt.scatter(ps, avgs)\n",
    "plt.xlabel(\"Proportion Classified as Heavy-Hitters\")\n",
    "plt.ylabel(\"Average Error\")\n",
    "plt.savefig(\"pgraph.png\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "final166.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
