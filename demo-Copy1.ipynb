{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipywidgets import interact\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import math\n",
    "import numpy as np\n",
    "import hashlib\n",
    "import scipy.stats as stats\n",
    "import json \n",
    "import nbinteract as nbi\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def square(x):\n",
    "    return x * x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "392a26d7286741f086d6bdb17db69e09",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=10, description='x', max=30, min=-10), Output()), _dom_classes=('widget-â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "interact(square, x=10);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "code_folding": [
     0,
     1
    ]
   },
   "outputs": [],
   "source": [
    "class CountMinSketch:\n",
    "    def __init__(self, eps, delta):\n",
    "        self.eps = eps\n",
    "        self.delta = delta\n",
    "        self.w = math.ceil(np.exp(1) / eps)\n",
    "        self.d = math.ceil(np.log(1 / delta))\n",
    "        self.tables = np.zeros((self.d, self.w))\n",
    "        self.backup = {}\n",
    "\n",
    "    def compute_hash(self, value, table_no):\n",
    "        fn = hashlib.md5()\n",
    "        inp = str(value) + str(0) + str(table_no)\n",
    "        fn.update(inp.encode())\n",
    "        out = int(fn.hexdigest(), 16)\n",
    "        return out % self.w\n",
    "\n",
    "    def count(self, value):\n",
    "        if str(value) in self.backup: \n",
    "            self.backup[str(value)] = self.backup[str(value)] + 1\n",
    "        else:\n",
    "            self.backup[str(value)] = 1\n",
    "        for i in range(self.d):\n",
    "            j = self.compute_hash(value, i)\n",
    "            self.tables[i][j] = self.tables[i][j] + 1\n",
    "\n",
    "    def estimate(self, value):\n",
    "        ests = []\n",
    "        for i in range(self.d):\n",
    "            j = self.compute_hash(value, i)\n",
    "            ests.append(self.tables[i][j])\n",
    "        return min(ests)\n",
    "\n",
    "    def real_estimate(self, value):\n",
    "        if str(value) in self.backup: return self.backup[str(value)]\n",
    "        return -1\n",
    "\n",
    "    def compute_size(self):\n",
    "        size = 0\n",
    "        for key in self.backup:\n",
    "            size += abs(self.backup[key])\n",
    "        return size\n",
    "\n",
    "    def save_counts(self, count_filename='counts.txt', actual_filename='backups.txt'):\n",
    "        np.savetxt(count_filename, self.tables)\n",
    "        with open(actual_filename, 'w') as fp: json.dump(self.backup, fp)\n",
    "\n",
    "    def load_counts(self, count_filename='counts.txt', actual_filename='backups.txt'):\n",
    "        with open(actual_filename, 'r') as fp: \n",
    "            temp = json.load(fp)\n",
    "            self.backup = temp\n",
    "        self.tables = np.loadtxt(count_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def load_data(cms, data):\n",
    "  for el in data:\n",
    "    cms.count(el)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def generate_sample(n=1000, dist='uniform', loc=0, scale=100, lambda_=5, s=100):\n",
    "    if dist == 'uniform':\n",
    "        float_sample = stats.uniform.rvs(loc, scale, n)\n",
    "        return [int(el) for el in float_sample]\n",
    "    if dist == 'zipf':\n",
    "        float_sample = stats.zipf.rvs(a, size=n)\n",
    "        return [(el) for el in float_sample]\n",
    "    if dist == 'exp':\n",
    "        float_sample = planck.rvs(lambda_, size=n)\n",
    "        return [int(el) for el in float_sample]\n",
    "    if dist == 'lognorm':\n",
    "        float_sample = lognorm.rvs(s=s, size=n)\n",
    "        return [int(el) for el in float_sample]\n",
    "    if dist == 'geometric':\n",
    "        float_sample =  geom.rvs(p, size=n)\n",
    "        return [int(el) for el in float_sample]\n",
    "    elif dist == 'normal':\n",
    "        float_sample = stats.norm.rvs(loc, scale, n)\n",
    "        return [int(el) for el in float_sample]\n",
    "    else:\n",
    "        return -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VISUALIZE ERROR PROBABILITY VS DELTA\n",
    "\n",
    "# compute empirical probability of error exceeding the threshold\n",
    "def compute_error_prob(cms, data, n):\n",
    "  err = []\n",
    "  for el in data:\n",
    "    err.append(cms.estimate(el) - cms.real_estimate(el))\n",
    "  avg_err = sum(err) / len(err)\n",
    "  max_err = max(err)\n",
    "  exceed = 0\n",
    "  for el in err:\n",
    "    if el > cms.eps * n:\n",
    "      exceed += 1\n",
    "  p = exceed / len(err)\n",
    "  return p, avg_err, max_err, err\n",
    "\n",
    "# run experiments on 10 values of delta interpolated between (min_delta, max_delta) and compute array of corresponding error probabilities\n",
    "def error_prob_vs_delta(n=100000, eps=0.4, min_delta=0.01, max_delta=0.1):\n",
    "  deltas = np.linspace(min_delta, max_delta, 10).tolist()\n",
    "  # deltas = [0.05, 0.1, 0.15, 0.2, 0.25, 0.3, 0.35, 0.4, 0.45, 0.5, 0.55, 0.6, 0.65, 0.7, 0.75, 0.8, 0.85, 0.9, 0.95, 1]\n",
    "  ps = []\n",
    "  for delta in deltas:\n",
    "    probs = 0\n",
    "    # Average probabilities across 3 trials\n",
    "    for i in range(3):\n",
    "      cms = CountMinSketch(eps, delta)\n",
    "      dt = generate_sample(n)\n",
    "      load_data(cms, dt)\n",
    "      p, avg_err, max_err, err = compute_error_prob(cms, dt, n)\n",
    "      probs += p\n",
    "    probs /= 3\n",
    "    ps.append(probs)\n",
    "  return deltas, ps\n",
    "\n",
    "# graphing helper function\n",
    "def graph_error_prob_vs_delta(deltas, ps, filename=\"p_vs_delta.png\"):\n",
    "  plt.scatter(deltas, ps)\n",
    "  plt.show()\n",
    "\n",
    "# actual code to run experiment:\n",
    "# deltas, ps = error_prob_vs_delta()\n",
    "# graph_error_prob_vs_delta(deltas, ps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Error: 0.312\n",
      "Maximum Error: 12.0\n",
      "Acceptable Threshold: 10.0\n",
      "Proportion of Errors Exceeding Threshold: 0.017\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# VISUALIZE HOW ERROR DISTRIBUTION CHANGES WITH EPS, DELTA, N ON UNIFORM DATA\n",
    "eps = 0.01\n",
    "delta = 0.05\n",
    "n = 1000\n",
    "threshold = eps * n\n",
    "sample = generate_sample(n=n)\n",
    "\n",
    "cms = CountMinSketch(eps, delta)\n",
    "load_data(cms, sample)\n",
    "\n",
    "p, avg_err, max_err, err = compute_error_prob(cms, sample, n)\n",
    "\n",
    "print(\"Average Error: \" + str(avg_err))\n",
    "print(\"Maximum Error: \" + str(max_err))\n",
    "print(\"Acceptable Threshold: \" + str(threshold))\n",
    "print(\"Proportion of Errors Exceeding Threshold: \" + str(p))\n",
    "\n",
    "plt.scatter(sample, err)\n",
    "plt.plot([min(sample), max(sample)], [threshold, threshold], color='red')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_sample(n=1000, dist='uniform', loc=0, scale=10000, lambda_=5, s=1, a=6.5):\n",
    "    print(dist)\n",
    "    if dist == 'uniform':\n",
    "        float_sample = stats.uniform.rvs(loc, scale, n)\n",
    "        return [int(el) for el in float_sample]\n",
    "    if dist == 'zipf':\n",
    "        float_sample = stats.zipf.rvs(a, size=n)\n",
    "        return [int(el) for el in float_sample]\n",
    "    if dist == 'exp':\n",
    "        float_sample = stats.planck.rvs(lambda_, size=n)\n",
    "        return [int(el) for el in float_sample]\n",
    "    if dist == 'lognorm':\n",
    "        float_sample = stats.lognorm.rvs(s=s, size=n)\n",
    "        return [int(el) for el in float_sample]\n",
    "    if dist == 'geometric':\n",
    "        float_sample =  stats.geom.rvs(p, size=n)\n",
    "        return [int(el) for el in float_sample]\n",
    "    elif dist == 'normal':\n",
    "        float_sample = stats.norm.rvs(loc, scale, n)\n",
    "        return [int(el) for el in float_sample]\n",
    "    else:\n",
    "        return -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_uniform(sample, eps, delta):\n",
    "    print(eps, delta)\n",
    "    eps = float(eps)\n",
    "    delta = float(delta)\n",
    "    # VISUALIZE HOW ERROR DISTRIBUTION CHANGES WITH EPS, DELTA, N ON UNIFORM DATA\n",
    "    threshold = eps * n\n",
    "    #sample = generate_sample(n=n)\n",
    "\n",
    "    cms = CountMinSketch(eps, delta)\n",
    "    load_data(cms, sample)\n",
    "\n",
    "    p, avg_err, max_err, err = compute_error_prob(cms, sample, n)\n",
    "\n",
    "    print(\"Average Error: \" + str(avg_err))\n",
    "    print(\"Maximum Error: \" + str(max_err))\n",
    "    print(\"Acceptable Threshold: \" + str(threshold))\n",
    "    print(\"Proportion of Errors Exceeding Threshold: \" + str(p))\n",
    "\n",
    "    #plt.scatter(sample, err)\n",
    "    #plt.plot([min(sample), max(sample)], [threshold, threshold], color='red')\n",
    "    return err\n",
    "    #plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "65aade2d603f45f5affbf807fe8753b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(interactive(children=(IntSlider(value=1000, description='n', max=2000, min=1), FloatSlider(valuâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "n = 1000\n",
    "#sample = generate_sample(n=n, dist=\"normal\")\n",
    "\n",
    "\n",
    "def get_sample(eps, delta, distribution, n): \n",
    "    return generate_sample(n=n, dist=distribution)\n",
    "\n",
    "\n",
    "\n",
    "nbi.scatter(get_sample, plot_uniform, n=(1,2000), eps=(0.01,1, 0.01), delta=(0.01, 1, 0.01), distribution={'normal': \"normal\", 'zipf': 'zipf', 'uniform': 'uniform', 'exp':'exp', 'geometric':'geometric', 'lognorm':'lognorm'})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hist_response_function(mean, sd, size=1000):\n",
    "    '''\n",
    "    Returns 1000 values picked at random from the normal\n",
    "    distribution with the mean and SD given.\n",
    "    '''\n",
    "    print(mean, sd)\n",
    "    return np.random.normal(loc=mean, scale=sd, size=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "scatter() missing 1 required positional argument: 'y_fn'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-130-c8548bde3693>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnbi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhist_response_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmean\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msd\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/nbinteract/plotting.py\u001b[0m in \u001b[0;36mcheck_options\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    166\u001b[0m                 )\n\u001b[1;32m    167\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 168\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    169\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcheck_options\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: scatter() missing 1 required positional argument: 'y_fn'"
     ]
    }
   ],
   "source": [
    "nbi.scatter(hist_response_function, mean=(0, 10), sd=(0, 2.0, 0.2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zipf\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 3,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1]"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_sample(n=n, dist=\"zipf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
